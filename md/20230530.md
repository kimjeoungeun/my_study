# 5월 30일 학습내용

### supervised learning
  : 정답(y)이 있어야함
- 보험비 예측 regression
- 여러개 중에 이거일 것 같다. classification

### unsupervised learning (clustering)
  : 정답이 없음(대충 이렇게 가자 ex.현대카드 그루핑)
 - k-means 클러스터링(그룹을 k개로 정의해야함)
    - k개의 그룹을 만듬(비슷한 애들끼리)_여러 그룹 가능
      : 랜덤 두개 점(데이터 아님) 찍고, 두 점 사이의 거리를 연결함(수직이등분하는 선을 찾음) -> 영역분리
      : -> 이 과정 반복한 후 평균을 구함 -> 점을 이동시킴 -> 두 점 사이의 거리를 연결함(수직이등분하는 선을 찾음)
      : ----------------> 반복하여 데이터가 변화가 없으면 끝응집할수록 좋음
      : 응집(중심부터 데이터까지의 거리가 가까울수록)할수록 데이터가 좋음
      : k-means ++ 알고리즘 (이상하게 랜덤잡는 것을 도와줌)
    - 컴퓨터한테 그룹이 1개일때, 2개일떄, 3개일때 등등 WCSS(중심부터 데이터까지의 거리의 제곱값)값을 구하라고 명령함
      : 엘보우메소드 : 효울적인 갯수는 엘보우에 있는 수(그룹수 대비 WCSS 선그래프에서 엘보우에 있는 그룹수가 효율적임)
   
#### 기본 셋팅 순서
1. 깃허브 레포지토리 생성
2. 리드미작성
3. 로컬에 클론
4. app.py 만들고 app_dash 환경 만들기
5. $streamlit run app.py 

### 실무용 연습
1. csv 파일을 업로드 할 수 있다.
2. 업로드한 csv 파일을 데이터 프레임으로 읽고
3. KMeans 클러스터링을 하기 위해 X로 사용할 컬럼을 설정할 수 있다.
4. WCSS를 확인하기 위한 그룹의 갯수를 정할 수 있다. 1~10개
5. 엘보우 메소드 차트를 화면에 표시
6. 그룹핑하고 싶은 갯수를 입력
7. 위에서 입력한 그룹의 갯수로 클러스터링하여 결과를 보여준다.


### 실무용 연습순서 확인
1. data를 csv 파일로 불러오기
2. 데이터 프레임 df로 읽음
3. X로 사용할 컬럼 설정하기
   1. 컬럼확인 .coloums
   2. 결측치 확인 및 제거 .inna().sum() , dropna()
   3. 결측치 제거 후 인덱스 초기화 .reset_index(inplace=True, drop=True)
   4. X값 주기 loc[:,:]
   5. X 컬럼 확인 후 인코딩 종류 고르기(레이블_2개이하, 원핫_3개이상)
   6. X 컬럼 확인시 인덱스로 가져온 후 타입 확인
   7. 인코딩 import
   8. 깡통 데이터프레임 만들기 : X_new=pd.DataFrame()
   9. for문 X 컬럼의 name 들이 문자냐 숫자냐?
   10. if 문 문자면 
      1. if 문 컬럼안의 데이터 종류가 3개 이상이면 원핫인코딩
        - 유니크의 데이터 정렬 sorted(1차원 시리즈이므로)
        - 시리즈를 2차원으로 변경 to_frame()
      2.  else 2개 이하면 레이블인코딩
        - fit_transform()
   11. else 숫자면 그대로 넣기


### ec2에 올리기
1. 깃허브 연동
2. 리눅스 ec2에서 cd github()로 이동
3. git 엔터 (깃 있나 확인)
4. git clone https://github.com/kje0058/KMeans_app.git
5. streamlit run app.py확인
6. 인바운드 규칙 편집 포트 열어둠
7. 터미널 접속을 끊어도 24식나 365일 스트림릿 돌아가도록
   - nohup streamlit run app.py &(1번만 실행할것, 계속 돌아감)
8. 돌아가는 프로세스 확인?
   - ps -ef | grep streamlit
9. 돌아가는 서버를 이제 끄려면?
   - kill processID

### 명령어
- top : 실행되어있는 top
- ps : 터미널에서 돌아가는 것
- ps -ef | grep streamlit : streamlit을 찾아주세요
- nohup streamlit run app.py --server.port 8505 & : 서버 지정해서 돌려주세요.
- streamlit run app.py --server.port 8505 : 잘 돌아가나 테스트로 확인해보세요.
- 포트 삭제하는법
  - ps -ef | grep streamlit 확인
  - kill processID


### 앱 대시보드 개발 프로젝트
- 개인 플젝(이력서에 사용할 포트폴리오)
  
1. 데이터 탐색 후 데이터 선택
2. 무엇을 분석할지 기획
3. 코랩에서 데이터 분석
4. 인공지능 개발이 가능한 데이터면 데이터 가공 및 학습
5. 앱 대시보드 화면 기획
6. 개발해서 ec2 적용
7. 깃허브 리드미 작성

#### 데이터 제공 사이트들
- http://idai.or.kr/data-search
- https://www.kaggle.com/
- https://www.data.go.kr/
- https://data.nps.or.kr/service/svc/data/search.do
- https://www.incheon.go.kr/data/index
- https://data.kostat.go.kr/sbchome/intro.do
- https://data.seoul.go.kr/
- https://data.gg.go.kr/portal/mainPage.do
- http://data.ex.co.kr/
- https://data.kma.go.kr/cmmn/main.do
- https://data.mfds.go.kr/cntnts/10
- https://www.bigdata-culture.kr/bigdata/user/main.do
- https://kdata.or.kr/datavoucher/is/selectPortalSearch.do


#### 참고 사이트
- 데이터 정리
  - https://partrita.github.io/posts/tidy-data/
  - https://brunch.co.kr/@data/12
  - 
- 